{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4Qiw872tJm5"
   },
   "source": [
    "### **spacy_text_classification : Exercise**\n",
    "\n",
    "\n",
    "- In this exercise, you are going to classify whether a given text belongs to one of possible classes ['BUSINESS', 'SPORTS', 'CRIME'].\n",
    "\n",
    "- you are going to use spacy for pre-processing the text, convert text to numbers and apply different classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bitKkWZnWGe",
    "outputId": "4779b05e-0078-4389-a57f-8cab8b9aa8ee"
   },
   "outputs": [],
   "source": [
    "#uncomment the below line and run this cell to install the large english model which is trained on wikipedia data\n",
    "\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nfwmJvdDnWIq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 16:41:45.080113: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 16:41:45.239802: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-22 16:41:45.239819: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-22 16:41:45.874237: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-22 16:41:45.874287: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-22 16:41:45.874292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#import spacy and load the language model downloaded\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOfdVUDOwC4y"
   },
   "source": [
    "### **About Data: News Category Classifier**\n",
    "\n",
    "Credits: https://www.kaggle.com/code/hengzheng/news-category-classifier-val-acc-0-65\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Text\n",
    "        - Category\n",
    "- Text are the description about a particular topic.\n",
    "- Category determine which class the text belongs to.\n",
    "- we have classes mainly of 'BUSINESS', 'SPORTS', 'CRIME' and comes under **Multi-class** classification Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "qA7qNgVenWL7",
    "outputId": "3f41a23c-af84-4774-9379-3247074a0084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Larry Nassar Blames His Victims, Says He 'Was ...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woman Beats Cancer, Dies Falling From Horse</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegas Taxpayers Could Spend A Record $750 Mill...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Richard Sherman Interception Literally Sh...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7 Things That Could Totally Kill Weed Legaliza...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Larry Nassar Blames His Victims, Says He 'Was ...     CRIME\n",
       "1       Woman Beats Cancer, Dies Falling From Horse      CRIME\n",
       "2  Vegas Taxpayers Could Spend A Record $750 Mill...    SPORTS\n",
       "3  This Richard Sherman Interception Literally Sh...    SPORTS\n",
       "4  7 Things That Could Totally Kill Weed Legaliza...  BUSINESS"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas library\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#read the dataset \"news_dataset.json\" provided and load it into dataframe \"df\"\n",
    "\n",
    "df = pd.read_json('word_vector.json')\n",
    "\n",
    "#print the shape of data\n",
    "print(df.shape)\n",
    "\n",
    "#print the top5 rows\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uMg291enWN0",
    "outputId": "fabf1b28-09f7-4aed-b43d-dc7d3365e321"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIME       2500\n",
       "SPORTS      2500\n",
       "BUSINESS    2500\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of labels \n",
    "\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rPu41FMfnWRc",
    "outputId": "0928da61-f016-4091-bc2a-0c9e447eccf5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Larry Nassar Blames His Victims, Says He 'Was ...</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woman Beats Cancer, Dies Falling From Horse</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegas Taxpayers Could Spend A Record $750 Mill...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Richard Sherman Interception Literally Sh...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7 Things That Could Totally Kill Weed Legaliza...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  label\n",
       "0  Larry Nassar Blames His Victims, Says He 'Was ...     CRIME      0\n",
       "1       Woman Beats Cancer, Dies Falling From Horse      CRIME      0\n",
       "2  Vegas Taxpayers Could Spend A Record $750 Mill...    SPORTS      1\n",
       "3  This Richard Sherman Interception Literally Sh...    SPORTS      1\n",
       "4  7 Things That Could Totally Kill Weed Legaliza...  BUSINESS      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column \"label_num\" which gives a unique number to each of these labels \n",
    "\n",
    "df['label'] = df.category.map({\n",
    "    'CRIME': 0,\n",
    "    'SPORTS': 1,\n",
    "    'BUSINESS': 2\n",
    "})\n",
    "\n",
    "#check the results with top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MChU23cwy2u"
   },
   "source": [
    "### **Preprocess the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gg2NzymmqRMG"
   },
   "outputs": [],
   "source": [
    "#use this utility function to preprocess the text\n",
    "#1. Remove the stop words\n",
    "#2. Convert to base form using lemmatisation\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TvMxzat8qtPb"
   },
   "outputs": [],
   "source": [
    "#create a new column \"preprocessed_text\" which store the clean form of given text [use apply and lambda function]\n",
    "\n",
    "df['preprocessed_text'] = df.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "UN7vG1Gqq2Kv",
    "outputId": "186e1189-816b-4650-9e38-a12b9bc8e1bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Larry Nassar Blames His Victims, Says He 'Was ...</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>0</td>\n",
       "      <td>Larry Nassar blame victim say victimize newly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woman Beats Cancer, Dies Falling From Horse</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>0</td>\n",
       "      <td>woman Beats Cancer die fall horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegas Taxpayers Could Spend A Record $750 Mill...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "      <td>Vegas Taxpayers spend Record $ 750 million New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Richard Sherman Interception Literally Sh...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "      <td>Richard Sherman Interception literally shake W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7 Things That Could Totally Kill Weed Legaliza...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2</td>\n",
       "      <td>7 thing totally kill Weed Legalization Buzz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  label  \\\n",
       "0  Larry Nassar Blames His Victims, Says He 'Was ...     CRIME      0   \n",
       "1       Woman Beats Cancer, Dies Falling From Horse      CRIME      0   \n",
       "2  Vegas Taxpayers Could Spend A Record $750 Mill...    SPORTS      1   \n",
       "3  This Richard Sherman Interception Literally Sh...    SPORTS      1   \n",
       "4  7 Things That Could Totally Kill Weed Legaliza...  BUSINESS      2   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0  Larry Nassar blame victim say victimize newly ...  \n",
       "1                  woman Beats Cancer die fall horse  \n",
       "2  Vegas Taxpayers spend Record $ 750 million New...  \n",
       "3  Richard Sherman Interception literally shake W...  \n",
       "4        7 thing totally kill Weed Legalization Buzz  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMT8vW6lxUCH"
   },
   "source": [
    "### **Get the spacy embeddings for each preprocessed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Totfo3RinWTQ"
   },
   "outputs": [],
   "source": [
    "#create a new column \"vector\" that store the vector representation of each pre-processed text\n",
    "\n",
    "df['vector'] = df.preprocessed_text.apply(lambda x:nlp(x).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "o6xPUWyFnWW0",
    "outputId": "b8c347c3-98ce-40ea-c51a-d4f0596b2d0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Larry Nassar Blames His Victims, Says He 'Was ...</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>0</td>\n",
       "      <td>Larry Nassar blame victim say victimize newly ...</td>\n",
       "      <td>[-0.34700856, 0.03156133, -0.21043956, -0.0024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woman Beats Cancer, Dies Falling From Horse</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>0</td>\n",
       "      <td>woman Beats Cancer die fall horse</td>\n",
       "      <td>[-0.23481816, 0.35125497, 0.011834003, -0.0055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegas Taxpayers Could Spend A Record $750 Mill...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "      <td>Vegas Taxpayers spend Record $ 750 million New...</td>\n",
       "      <td>[0.053351898, 0.08053064, -0.05101806, -0.1991...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This Richard Sherman Interception Literally Sh...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "      <td>Richard Sherman Interception literally shake W...</td>\n",
       "      <td>[-0.038867258, 0.28459162, 0.071352966, -0.045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7 Things That Could Totally Kill Weed Legaliza...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>2</td>\n",
       "      <td>7 thing totally kill Weed Legalization Buzz</td>\n",
       "      <td>[-0.20180944, 0.11867001, 0.0036708585, -0.189...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  label  \\\n",
       "0  Larry Nassar Blames His Victims, Says He 'Was ...     CRIME      0   \n",
       "1       Woman Beats Cancer, Dies Falling From Horse      CRIME      0   \n",
       "2  Vegas Taxpayers Could Spend A Record $750 Mill...    SPORTS      1   \n",
       "3  This Richard Sherman Interception Literally Sh...    SPORTS      1   \n",
       "4  7 Things That Could Totally Kill Weed Legaliza...  BUSINESS      2   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  Larry Nassar blame victim say victimize newly ...   \n",
       "1                  woman Beats Cancer die fall horse   \n",
       "2  Vegas Taxpayers spend Record $ 750 million New...   \n",
       "3  Richard Sherman Interception literally shake W...   \n",
       "4        7 thing totally kill Weed Legalization Buzz   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.34700856, 0.03156133, -0.21043956, -0.0024...  \n",
       "1  [-0.23481816, 0.35125497, 0.011834003, -0.0055...  \n",
       "2  [0.053351898, 0.08053064, -0.05101806, -0.1991...  \n",
       "3  [-0.038867258, 0.28459162, 0.071352966, -0.045...  \n",
       "4  [-0.20180944, 0.11867001, 0.0036708585, -0.189...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ok6jIl3yHmT"
   },
   "source": [
    "**Train-Test splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FmVG4s2onWYz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.vector, \n",
    "                                                 df.label, \n",
    "                                                 test_size = 0.2, \n",
    "                                                 random_state = 2022)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaneRpe_yPN8"
   },
   "source": [
    "**Reshape the X_train and X_test so as to fit for models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsW_POgXzE48",
    "outputId": "4367a34c-c9fc-41e2-b1ae-29577648f32b"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#reshapes the X_train and X_test using 'stack' function of numpy. Store the result in new variables \"X_train_2d\" and \"X_test_2d\"\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RKhDtigyfDm"
   },
   "source": [
    "**Attempt 1:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "\n",
    "- use Decision Tree as the classifier.\n",
    "\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12078159,  0.1251742 ,  0.24247845, ..., -0.23317586,\n",
       "        -0.12946762,  0.14674115],\n",
       "       [-0.08704231,  0.15871203, -0.09212321, ..., -0.13176163,\n",
       "         0.10281384,  0.08144095],\n",
       "       [-0.42832655,  0.23338538,  0.1606854 , ..., -0.3532798 ,\n",
       "         0.1205477 , -0.01483208],\n",
       "       ...,\n",
       "       [-0.166941  , -0.01782378,  0.076621  , ..., -0.14866823,\n",
       "         0.02668255,  0.17461611],\n",
       "       [-0.17725699,  0.09010557,  0.04612279, ...,  0.09186578,\n",
       "        -0.03186679, -0.02291214],\n",
       "       [-0.14895883,  0.1750557 , -0.0813623 , ...,  0.10252918,\n",
       "         0.09775136,  0.05753722]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPxr0V68zE-y",
    "outputId": "15d1877c-5cf7-4ca0-de9b-522f3c6178ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       491\n",
      "           1       0.74      0.70      0.72       506\n",
      "           2       0.72      0.76      0.74       503\n",
      "\n",
      "    accuracy                           0.74      1500\n",
      "   macro avg       0.74      0.74      0.74      1500\n",
      "weighted avg       0.74      0.74      0.74      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# all_train_embed = scaler.fit_transform(X_train_2d)\n",
    "# all_test_embed = scaler.fit_transform(X_test_2d)\n",
    "\n",
    "#1. creating a Decision Tree model object\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "model.fit(X_train_2d, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "y_pred = model.predict(X_test_2d)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQdHIem6zANo"
   },
   "source": [
    "**Attempt 2:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "- use MultinomialNB as the classifier after applying the MinMaxscaler.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJiRqXsRzE7F",
    "outputId": "b904000a-c812-4e2e-eb17-7594bc087838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       532\n",
      "           1       0.79      0.96      0.87       392\n",
      "           2       0.91      0.85      0.88       576\n",
      "\n",
      "    accuracy                           0.87      1500\n",
      "   macro avg       0.87      0.88      0.87      1500\n",
      "weighted avg       0.88      0.87      0.88      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "#doing scaling because Negative values will not pass into Naive Bayes models\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "all_train_embed = scaler.fit_transform(X_train_2d)\n",
    "all_test_embed = scaler.fit_transform(X_test_2d)\n",
    "\n",
    "#1. creating a MultinomialNB model object \n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "#2. fit with all_train_embeddings(scaled) and y_train\n",
    "\n",
    "model.fit(all_train_embed, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "y_pred = model.predict(all_test_embed)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJbv-mxR0n4r"
   },
   "source": [
    "**Attempt 3:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "- use KNeighborsClassifier as the classifier after applying the MinMaxscaler.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU0BNgVuzFAv",
    "outputId": "d242d458-2474-4f3d-9f61-0c74b184bb2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90       541\n",
      "           1       0.88      0.93      0.90       453\n",
      "           2       0.87      0.92      0.90       506\n",
      "\n",
      "    accuracy                           0.90      1500\n",
      "   macro avg       0.90      0.90      0.90      1500\n",
      "weighted avg       0.90      0.90      0.90      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#1. creating a KNN model object\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "model.fit(X_train_2d, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "y_pred = model.predict(X_test_2d)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKE0byVj04LO"
   },
   "source": [
    "**Attempt 4:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "- use RandomForestClassifier as the classifier after applying the MinMaxscaler.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9c8jZEUzOjr",
    "outputId": "49e97ed9-59e1-4e90-e53c-08bffbc54abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       522\n",
      "           1       0.83      0.92      0.88       433\n",
      "           2       0.88      0.86      0.87       545\n",
      "\n",
      "    accuracy                           0.87      1500\n",
      "   macro avg       0.87      0.88      0.87      1500\n",
      "weighted avg       0.88      0.87      0.87      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#1. creating a Random Forest model object\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "model.fit(all_train_embed, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "y_pred = model.predict(all_test_embed)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5DsqLBp1BGR"
   },
   "source": [
    "**Attempt 5:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "- use GradientBoostingClassifier as the classifier after applying the MinMaxscaler.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YF-3k8RzzOmf",
    "outputId": "8eff0156-6b5a-445f-bc0b-69ba2af8c4bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       509\n",
      "           1       0.81      0.95      0.87       405\n",
      "           2       0.93      0.85      0.89       586\n",
      "\n",
      "    accuracy                           0.88      1500\n",
      "   macro avg       0.88      0.89      0.88      1500\n",
      "weighted avg       0.89      0.88      0.89      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "model.fit(all_train_embed, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "y_pred = model.predict(all_test_embed)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjatMREK15os"
   },
   "source": [
    "**Print the confusion Matrix with the best model got**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "6jlO1jfx145r",
    "outputId": "f45972c2-adb1-4bd5-e699-092400ea527d"
   },
   "outputs": [],
   "source": [
    "#finally print the confusion matrix for the best model: GradientBoostingClassifier\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Solution**](./spacy_word_embeddings_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
